{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical Data Extractor File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemdataextractor import Document\n",
    "from chemdataextractor.doc import Sentence, Paragraph\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from xml.etree import cElementTree as ET\n",
    "import pickle\n",
    "import inflect #used to convert words from singular to plural and opposite\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various filter functions\n",
    "#function takes a chemical and removes metadata matches and \n",
    "#only non-characters chemicals\n",
    "def filter_match(string,bad_matches):\n",
    "    \n",
    "    noMatch=True\n",
    "    #REGEXes\n",
    "    title_regex=re.compile('^[A-Z]{2,3}\\d+ *\\/* *[A-Z]{0,3}\\d+.*$')\n",
    "    char_only_regex=re.compile('^[^A-Za-z]*$')\n",
    "    \n",
    "    \n",
    "    if char_only_regex.match(string)!=None:\n",
    "        noMatch=False\n",
    "    elif title_regex.match(string) !=None:\n",
    "        noMatch=False\n",
    "    \n",
    "    if not noMatch:\n",
    "        bad_matches.add(string)\n",
    "  \n",
    "    return noMatch\n",
    "\n",
    "#builds possible strings for removing possible overlap abbreviations\n",
    "#patents often have spacing issues and this finds all possible spacings for removal\n",
    "def create_poss_strings(l):\n",
    "    new_strings=set()\n",
    "    new_strings.add(l[0])\n",
    "    for i in range(1,len(l)):\n",
    "        old_strings=new_strings\n",
    "        new_strings=set()\n",
    "        for s in old_strings:\n",
    "            new_strings.add(s+l[i])\n",
    "            new_strings.add(s+\" \"+l[i])\n",
    "            \n",
    "    return new_strings\n",
    "\n",
    "#full function that fills out possible matches for an abbreviation record\n",
    "#main function for function before that creates the string to get all possible\n",
    "#spacings for that string using create_poss_strings function\n",
    "#takes in a list (its a string broken into word defined by the chemical data extractor \n",
    "#abbreviations) and returns a set of possible matches to remove\n",
    "def add2non_abrev_matches(full_list):\n",
    "    #preprocess to get words\n",
    "    first_words=None\n",
    "    if full_list[-1]==\")\":\n",
    "        isParen=True\n",
    "        first_words=full_list[0].split(\"(\")\n",
    "\n",
    "        rec_list=first_words+full_list[1:-1]\n",
    "    else:\n",
    "        rec_list=full_list\n",
    "\n",
    "\n",
    "\n",
    "    non_abrev_matches=create_poss_strings(rec_list)\n",
    "   \n",
    "    try:\n",
    "        #get singular and plural versions of chemicals\n",
    "        copy_list=rec_list.copy()\n",
    "        end_idx=-1\n",
    "        if first_words!=None:\n",
    "            idx=-2\n",
    "        if p.singular_noun(copy_list[end_idx])==False:\n",
    "            copy_list[end_idx]=p.plural(copy_list[end_idx])\n",
    "            non_abrev_matches=non_abrev_matches.union(create_poss_strings(copy_list))\n",
    "        else:\n",
    "            copy_list[end_idx]=p.singular_noun(copy_list[end_idx])\n",
    "            non_abrev_matches=non_abrev_matches.union(create_poss_strings(copy_list))\n",
    "    except:\n",
    "        pass\n",
    "    #put back in any parenthesis and return\n",
    "    for s in list(non_abrev_matches):\n",
    "        split_s=s.split()\n",
    " \n",
    "        if first_words!=None and split_s[0]==first_words[0]:\n",
    "            new_str=s[:len(split_s[0])]+\"(\"+s[len(split_s[0])+1:]+\")\"\n",
    "\n",
    "            non_abrev_matches.add(new_str)\n",
    "    return non_abrev_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chemical Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackabuse.com/reading-and-writing-xml-files-in-python/\n",
    "\n",
    "#tree = ET.parse(\"chemical-patents-xml/AU-2014316839-B2.xml\")\n",
    "\n",
    "#takes in a file name and returns all the chemicals in a document\n",
    "#all chemicals and abbreviations are in lower case\n",
    "def get_chemical_set(filename):\n",
    "\n",
    "    chem_matches=set()\n",
    "    bad_matches=set()\n",
    "    non_abrev_matches=set()\n",
    "    non_chem_matches=set()\n",
    "    \n",
    "    #http://www2.hawaii.edu/~takebaya/cent110/xml_parse/xml_parse.html\n",
    "    #get all information from claims, descriptions and abstract\n",
    "    #als make sure its just english\n",
    "    claims,abstract,description=[],[],[]\n",
    "    soup = BeautifulSoup(open(filename, 'r'), 'xml')\n",
    " \n",
    "    claims_soup=soup.find_all('claims')\n",
    "\n",
    "    for i in range(0, len(claims)):\n",
    "        if claims_soup[i]['lang']==\"EN\":\n",
    "            claims.append(claims_soup[i].get_text())\n",
    " \n",
    "    description_soup=soup.find_all('description')\n",
    "    for i in range(0, len(description_soup)):\n",
    "        if description_soup[i]['lang']==\"EN\":\n",
    "            description.append(description_soup[i].get_text())\n",
    "\n",
    "    abstract_soup=soup.find_all('abstract')\n",
    "\n",
    "    for i in range(0, len(abstract)):\n",
    "        if abstract_soup[i]['lang']==\"EN\":\n",
    "            abstract.append(abstract_soup[i].get_text())\n",
    "    \n",
    "    for sect_idx,section in enumerate([abstract,description,claims]):\n",
    "    \n",
    "        for text in section:\n",
    "            #put string into package and get back variable holding various information\n",
    "            doc=Document(text) \n",
    "            #creates set of chemicals that map to abbreviations that are to be removed from final words\n",
    "            non_abbrev=set()\n",
    "            if len(doc.abbreviation_definitions)>0:\n",
    "                \n",
    "                for abbrev in doc.abbreviation_definitions:\n",
    "              \n",
    "                    if abbrev[2]!=None: \n",
    "                        chem_matches.add(abbrev[0][0].lower())\n",
    "                    else:\n",
    "                        non_chem_matches.add(abbrev[0][0])\n",
    "                    non_abrev_matches=non_abrev_matches.union(add2non_abrev_matches(abbrev[1]))\n",
    "                    non_abbrev.add(\" \".join(abbrev[1]))\n",
    "            #now iterate through chemicals\n",
    "            for span_chem in doc.cems:\n",
    "                chemical=span_chem.text\n",
    "                paragraph = Paragraph(chemical)\n",
    "                for sentence in paragraph.sentences:\n",
    "                    tokens={value[1] for value in sentence.pos_tagged_tokens}\n",
    "                    #remove based on part of speech tags\n",
    "                    if 'CC' in tokens or 'IN' in tokens or 'TO' in tokens or 'RB' in tokens or 'DT' in tokens:\n",
    "                        continue\n",
    "                    if 'VBN' in tokens and sentence.pos_tagged_tokens[0][1]!='VBN':\n",
    "                        continue\n",
    "                    if sentence in non_abbrev:\n",
    "                        continue\n",
    "                    if (not chemical in bad_matches) and filter_match(chemical,bad_matches) and chemical[0]!=\"-\":\n",
    "                        if '``' in tokens:\n",
    "                            chemical=\" \".join([word[0]  for word in sentence.pos_tagged_tokens if word[1]!='``'])\n",
    "\n",
    "                        chem_matches.add(chemical.lower())\n",
    "                        #get sub chemical components by splitting by non character words\n",
    "                        subwords=re.split('[^a-zA-Z]', chemical.lower())\n",
    "                        for subw in subwords:\n",
    "                            if len(subw)>0:\n",
    "                                chem_matches.add(subw)\n",
    "\n",
    "                                    \n",
    "                                \n",
    "    chem_matches=chem_matches-non_abrev_matches      \n",
    "\n",
    "    return chem_matches\n",
    "\n",
    "#None exhaustive list of various filters\n",
    "#Lower case all letters\n",
    "#remove - if its the first character (probably gotten by different point as it was cut off)\n",
    "#POS tagging remove IN and TO. remove Verbs iff not first word\n",
    "#Only include abbreviations. try to catch all possible permutations for an abbreviation\n",
    "#Regex to remove records with no characters, and possible names of patent information\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in a folder and gets all chemicals. will write to specified folder\n",
    "#where each file corresponds to chemicals from a patent\n",
    "folder=\"patent_chemicals\"\n",
    "orig_folder=\"chemical-patents-xml\"\n",
    "no_chems_extracted=set()\n",
    "for file_idx,filename in enumerate(os.listdir(orig_folder)):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        start=time.time()\n",
    "        chem_matches=get_chemical_set(f\"{orig_folder}/\"+filename)\n",
    "       \n",
    "        #dont add file if no chemicals matched\n",
    "        if len(chem_matches)==0:\n",
    "            no_chems_extracted.add(filename)\n",
    "            numtime=time.time()-start\n",
    "\n",
    "            continue\n",
    "        numtime=time.time()-start\n",
    "        print(file_idx,numtime)\n",
    "        print(filename,len(chem_matches))\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        \n",
    "        with open(f\"{folder}/{filename[:-4]}_words.txt\",'wb') as f:\n",
    "            pickle.dump(chem_matches, f)\n",
    "            \n",
    "#will also write to file patents that no chemicals were extracted\n",
    "fd=open('./no_chem_extracted.txt','wt')\n",
    "for file in no_chems_extracted:\n",
    "\n",
    "    fd.write(file)\n",
    "    fd.write(\"\\n\")\n",
    "fd.close()\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Debug functions functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length Chemical Matches\",len(chem_matches),\"|\",\"Length Bad Matches\",len(bad_matches),\"|\",\"Length Non Abbrev\",len(non_abrev_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print chemicals\n",
    "for idx,match in enumerate(chem_matches):\n",
    "    print(\"Index {}:\".format(idx+1),match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just prints chemicals for a document. helpful to understaind how chemical data extractor words\n",
    "soup = BeautifulSoup(open(\"chemical-patents-xml/EP-1609024-B1.xml\", 'r'), 'xml')\n",
    " \n",
    "claims,abstract,description=[],[],[]\n",
    "claims_soup=soup.find_all('claims')\n",
    "\n",
    "for i in range(0, len(claims)):\n",
    "    if claims_soup[i]['lang']==\"EN\":\n",
    "        claims.append(claims_soup[i].get_text())\n",
    "\n",
    "description_soup=soup.find_all('description')\n",
    "for i in range(0, len(description_soup)):\n",
    "    if description_soup[i]['lang']==\"EN\":\n",
    "        description.append(description_soup[i].get_text())\n",
    "\n",
    "abstract_soup=soup.find_all('abstract')\n",
    "\n",
    "for i in range(0, len(abstract)):\n",
    "    if abstract_soup[i]['lang']==\"EN\":\n",
    "        abstract.append(abstract_soup[i].get_text())\n",
    "doc=Document(description[0])\n",
    "for c in doc.cems:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
